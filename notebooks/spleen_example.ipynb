{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from monai import utils, transforms, networks, data, engines, losses, metrics, visualize, config, inferers, apps\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import dotenv\n",
    "import rootutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootutils is not working but maybe that's because this is a .ipynb and not a .py\n",
    "# root = rootutils.setup_root(__file__, dotenv=True, pythonpath=True, cwd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of .env file:\n",
      "  MONAI_DATA_DIRECTORY = /home/sasank/projects/med-start/data\n",
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.0\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/monai/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.13.1\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: 4.7.3\n",
      "TorchVision version: 0.17.2+cu121\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 6.0.0\n",
      "pandas version: 2.2.2\n",
      "einops version: 0.7.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 2.12.1\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "# print the contents of the .env file\n",
    "print(\"Contents of .env file:\")\n",
    "for key in os.environ:\n",
    "    if key.startswith(\"MONAI_\"):\n",
    "        print(f\"  {key} = {os.environ[key]}\")\n",
    "\n",
    "config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datamodule\n",
    "class MyDataModule(L.LightningDataModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Make sure data directory exists\n",
    "        directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "        if directory is not None:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        if directory is None or not os.path.exists(directory):\n",
    "            # throw an error if the data directory is not set\n",
    "            raise ValueError(\"Please set the environment variable MONAI_DATA_DIRECTORY to a valid directory.\")\n",
    "        # root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "        self.root_dir = directory\n",
    "        print(self.root_dir)\n",
    "\n",
    "        self.data_dir = os.path.join(self.root_dir, \"Task09_Spleen\")\n",
    "        # self.root_dir = '/home/sasank/projects/med-start/data/'\n",
    "        print(self.root_dir)\n",
    "        print(self.data_dir)\n",
    "\n",
    "        utils.misc.set_determinism(seed=0)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \n",
    "        # download the data if it's not already downloaded\n",
    "        resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "        md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "        compressed_file = os.path.join(self.root_dir, \"Task09_Spleen.tar\")\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            # print the directory it will be downloaded to\n",
    "            print(f\"Data will be downloaded to {self.data_dir}\")\n",
    "            apps.download_and_extract(resource, compressed_file, self.root_dir, md5)\n",
    "    \n",
    "    def setup(self):\n",
    "        # set up the correct data path\n",
    "        train_images = sorted(glob.glob(os.path.join(self.data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "        train_labels = sorted(glob.glob(os.path.join(self.data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "        data_dicts = [\n",
    "            {\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)\n",
    "        ]\n",
    "        print(f\"training data: {len(data_dicts)}\")\n",
    "        # print the first few items to check\n",
    "        print(data_dicts[:2])\n",
    "        train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        # set_determinism(seed=42)\n",
    "        # set_determinism()\n",
    "\n",
    "        train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                transforms.RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(96, 96, 96), pos=1, neg=1, num_samples=4),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_ds = data.CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "        self.val_ds = data.CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(self.train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return data.DataLoader(self.val_ds, batch_size=2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sasank/projects/med-start/data\n",
      "/home/sasank/projects/med-start/data\n",
      "/home/sasank/projects/med-start/data/Task09_Spleen\n",
      "training data: 41\n",
      "[{'image': '/home/sasank/projects/med-start/data/Task09_Spleen/imagesTr/spleen_10.nii.gz', 'label': '/home/sasank/projects/med-start/data/Task09_Spleen/labelsTr/spleen_10.nii.gz'}, {'image': '/home/sasank/projects/med-start/data/Task09_Spleen/imagesTr/spleen_12.nii.gz', 'label': '/home/sasank/projects/med-start/data/Task09_Spleen/labelsTr/spleen_12.nii.gz'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:06<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "dm = MyDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightningModule\n",
    "class MyNetwork(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = networks.nets.UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=networks.Layers.Norm.BATCH,\n",
    "        )\n",
    "        self.loss = losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        # self.post_pred = inferers.Activation(inferers.Argmax(), to_onehot=True, num_classes=2)\n",
    "        # self.post_label = inferers.OneHot(num_classes=2)\n",
    "        self.post_pred = transforms.Compose([transforms.EnsureType(\"tensor\", device=\"cpu\"), transforms.AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = transforms.Compose([transforms.EnsureType(\"tensor\", device=\"cpu\"), transforms.AsDiscrete(to_onehot=2)])\n",
    "        # self.post_pred and self.post_label are for the case when the model output is not one-hot encoded and the labels are one-hot encoded.\n",
    "        # These transforms are run after the model output and the labels are retrieved from the data loader.\n",
    "        self.DiceMetric = metrics.DiceMetric(include_background=False, reduction=\"mean\")\n",
    "        # You would want to include background when you have a background class in your data.\n",
    "        # You would not want to include background when you don't have a background class in your data.\n",
    "        # Could you not want to include background when you have a background class in your data?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "        outputs = inferers.sliding_window_inference(inputs, roi_size=(96, 96, 96), sw_batch_size=4, predictor=self.model)\n",
    "        # outputs = self.model(inputs)\n",
    "        loss = self.loss(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
